import pandas as pd
import joblib
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc
import matplotlib.pyplot as plt

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df = pd.read_csv('credit_cleaned.csv')
df_encoded = pd.get_dummies(df)

X = df_encoded.drop('loan_status', axis=1)
y = df_encoded['loan_status']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# –û–±—É—á–∞–µ–º XGBoost
print("–û–±—É—á–∞–µ–º XGBoost...")
xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5)
xgb_model.fit(X_train, y_train)

# –ó–∞–≥—Ä—É–∂–∞–µ–º Baseline –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
lr_model = joblib.load('baseline_model.pkl')

# 4. –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
lr_probs = lr_model.predict_proba(X_test)[:, 1]
xgb_probs = xgb_model.predict_proba(X_test)[:, 1]

lr_auc = roc_auc_score(y_test, lr_probs)
xgb_auc = roc_auc_score(y_test, xgb_probs)

print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
print(f"Logistic Regression AUC: {lr_auc:.4f}")
print(f"XGBoost AUC: {xgb_auc:.4f}")

# 5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Feature Importance
plt.figure(figsize=(10, 6))
feat_importances = pd.Series(xgb_model.feature_importances_, index=X.columns)
feat_importances.nlargest(10).plot(kind='barh')
plt.title('–¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –≤—ã–¥–∞—á–∏ –∫—Ä–µ–¥–∏—Ç–∞')
plt.tight_layout()
plt.savefig('feature_importance.png')
print("\nüìà –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ feature_importance.png")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
joblib.dump(xgb_model, 'best_credit_model.pkl')
# –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
joblib.dump(X.columns.tolist(), 'model_columns.pkl')
print("–ú–æ–¥–µ–ª—å XGBoost –∏ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")